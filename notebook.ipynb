{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the huggingface transformers library\n",
    "%pip install -U sentence-transformers\n",
    "# Install the ipywidgets library\n",
    "%pip install ipywidgets\n",
    "# Install the python-graphql-client library\n",
    "%pip install python-graphql-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "dgraph_hostname = \"localhost\"\n",
    "\n",
    "import socket\n",
    "\n",
    "def check_port(url, port):\n",
    "    \"\"\"\n",
    "    check_port returns true if the port at the url is accepting connections\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        sock.settimeout(3)  # Set a timeout value for the connection attempt\n",
    "        result = sock.connect_ex((url, port))\n",
    "        sock.close()\n",
    "        if result == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except socket.error:\n",
    "        return False\n",
    "\n",
    "# check Dgraph ports to ensure access\n",
    "dgraph_http_port = 8080\n",
    "if not check_port(dgraph_hostname, dgraph_http_port):\n",
    "    raise Exception(f\"HTTP Port {dgraph_http_port} at {dgraph_hostname} not responding, is the server running?\")\n",
    "\n",
    "print(\"Required port(s) accepting connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Apply the schema to Dgraph\n",
    "\n",
    "admin_url = f'http://{dgraph_hostname}:{dgraph_http_port}/admin/schema'\n",
    "# Load the schema file\n",
    "schema_file = \"schema.graphql\"\n",
    "schema = open(schema_file).read()\n",
    "headers = {\n",
    "    'Content-Type': 'application/octet-stream',\n",
    "}\n",
    "response = requests.post(admin_url, data=schema, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    message = response.text\n",
    "    if \"errors\" in message:\n",
    "        raise Exception(message)\n",
    "    print(\"Schema applied successfully\")\n",
    "else:\n",
    "    raise Exception(f\"Error applying schema: {response.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handy browser utility from Apollo\n",
    "\n",
    "https://studio.apollographql.com/sandbox/explorer?endpoint=http://localhost:8080/graphql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding model using the sentence-transformers library\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "from python_graphql_client import GraphqlClient\n",
    "from episode_importer import load_episodes\n",
    "from script_importer import load_lines\n",
    "\n",
    "# Load episodes and lines into Dgraph, pass the model to the line and episodes importer\n",
    "\n",
    "client = GraphqlClient(endpoint=f\"http://{dgraph_hostname}:{dgraph_http_port}/graphql\")\n",
    "load_episodes(client, model)\n",
    "load_lines(client, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_graphql_client import GraphqlClient\n",
    "\n",
    "client = GraphqlClient(endpoint=f\"http://{dgraph_hostname}:{dgraph_http_port}/graphql\")\n",
    "\n",
    "# Query Dgraph for the most similar lines to the input line\n",
    "line = \"Feelings of intense dread\"\n",
    "line_embedding = model.encode([line])[0].tolist()\n",
    "query = \"\"\"\n",
    "    query byLine($vector: [Float!]!) {    \n",
    "        querySimilarLineByEmbedding(by: text_v, topK: 3, vector: $vector) {\n",
    "            id\n",
    "            text\n",
    "            vector_distance\n",
    "            episode {\n",
    "                identifier\n",
    "                title\n",
    "                summary\n",
    "                lines(first: 5, order: {asc: number}) {\n",
    "                    number\n",
    "                    text\n",
    "                    character {\n",
    "                        name\n",
    "                        lines(first: 5, order: {asc: number}) {\n",
    "                            text\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            character {\n",
    "                name\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "variables = {\n",
    "    \"vector\": line_embedding\n",
    "}\n",
    "data = client.execute(query=query, variables=variables)\n",
    "# iterate results, pull out the text, episode, and character\n",
    "for line in data[\"data\"][\"querySimilarLineByEmbedding\"]:\n",
    "    print(f\"{line['episode']['title']} ({line['episode']['identifier']}) - {line['character']['name']}: {line['text']} (distance: {line['vector_distance']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(data[\"data\"][\"querySimilarLineByEmbedding\"][0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Dgraph for the most similar episodes to the input sentence\n",
    "sentence = \"Joys of the holidays\"\n",
    "sentence_embedding = model.encode([sentence])[0].tolist()\n",
    "query = \"\"\"\n",
    "    query byEpisiode($vector: [Float!]!) {    \n",
    "        querySimilarEpisodeByEmbedding(by: summary_v, topK: 3, vector: $vector) {\n",
    "            identifier\n",
    "            title\n",
    "            summary\n",
    "            vector_distance\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "variables = {\n",
    "    \"vector\": sentence_embedding\n",
    "}\n",
    "data = client.execute(query=query, variables=variables)\n",
    "# iterate results, pull out the episode, summary, and distance\n",
    "for episode in data[\"data\"][\"querySimilarEpisodeByEmbedding\"]:\n",
    "    print(f\"{episode['identifier']} {episode['title']} - {episode['summary']} (distance: {episode['vector_distance']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query similar episodes by episode identifier\n",
    "\n",
    "query = \"\"\"\n",
    "    query {\n",
    "        querySimilarEpisodeById(by: summary_v, topK: 3, identifier: \"S03E12\") {\n",
    "            identifier\n",
    "            title\n",
    "            summary\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "data = client.execute(query=query)\n",
    "# iterate results, pull out the episode, summary, and distance\n",
    "for episode in data[\"data\"][\"querySimilarEpisodeById\"]:\n",
    "    print(f\"{episode['identifier']} {episode['title']} - {episode['summary']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats\n",
    "\n",
    "* The data generated in this Docker container is not persisted\n",
    "* There is no auto-updating of the vectors, for instance if I update an Episode summary, I'll also need to regenerate the vector embedding. Dgraph's parent, Hypermode I think is working on that feature and other related things\n",
    "* There seems to be some issues with cascading queries when using the generated querySimilar<Object>ByEmbedding endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issues with cascading queries with the vector searching (Part 1)\n",
    "\n",
    "# For instance, this cascading query works as expected\n",
    "\n",
    "query = \"\"\"\n",
    "  query {\n",
    "    queryLine(filter: { text: { anyofterms: \"bagel\" } }) @cascade {\n",
    "      text\n",
    "      episode {\n",
    "        season(filter: { number: { eq: 9 } }) {\n",
    "          number\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\"\"\"\n",
    "data = client.execute(query=query)\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issues with cascading queries with the vector searching (continued)\n",
    "\n",
    "# This cascading query is NOT working with the built-in similarity search\n",
    "sentence = \"Food\"\n",
    "sentence_embedding = model.encode([sentence])[0].tolist()\n",
    "query = \"\"\"\n",
    "    query byLine($vector: [Float!]!) {    \n",
    "        querySimilarLineByEmbedding(by: text_v, topK: 3, vector: $vector) @cascade {\n",
    "            text\n",
    "            vector_distance\n",
    "            episode {\n",
    "              identifier\n",
    "              season(filter: { number: {eq: 9} }) {\n",
    "                number\n",
    "              }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "variables = {\n",
    "    \"vector\": sentence_embedding\n",
    "}\n",
    "data = client.execute(query=query, variables=variables)\n",
    "print(json.dumps(data, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
